* Theoretical performance peak
* We only include throughputs
* Latency is not included, as it can be hidden
* Depending on the CPU, if it has separate addition and multiplication units
  (Sandy Bridge), then + and * operations are counted separately and executed
  in parallel. For CPU (Haswell and up), the + and * operations seem to share
  execution units (ports), so we add them together for the performance peak.
* The maximum throughput is typically achieved by engaging all units. Typically
  it's one operation per cycle, and if we have 4 units, its 0.25. If there are
  2 units, its 0.5. --- this detail is not really needed.
* ARM and Intel results
* Graphs: Read, write, multiplication / fma, sin. Compare clang, gfortran,
  assembly; and the theoretical peak
* The idea is to use read/write/multiplication/fma benchmarks as anchors to
  determine/measure the correct CPU frequency; then we can use the frequency to
  measure the actual kernel (kernel_sin1 in our case)
* This method is completely general, works for any CPU and does not depend on
  low level details of the CPU operation, besides knowing how + and * and fma
  operations are executed (whether in parallel or in sequence)
* Write up the throughputs for the CPUs that we will use.
* "Anchor" (find a better word) is used to calibrate our measurements /
  detectors

* Why assembly: we don't want to be using assembly. But it's great for the
  simple benchmarks as we force the cpu to actually do the job (say only
  reading array), as otherwise the compiler optimizes it out. Without
  optimizaitons there are tons of ineffective instructions, so not running at
  peak. With optimizations on, it optimizes the useless read away, so we can't
  benchmark it. In assembly we are actually benchmarking the read.

  * Great for the read / write / multiplication / fma benchmarks to use as
    anchors --- the assembly does not change, once we trust it, we can always
    use it as a robust "anchor". 
  * The other reason is that we can apply the loop unrolling and rearrangement
    by hand, no need to fight the compiler to produce the correct assembly.
  * Sometimes it's the easiest to achieve the peak in assembly to know it's
    possible, and then the next job is to figure out how to achieve it via
    LLVM, and finally in the compiler itself. (Then it's just "fighting" the
    compiler.)

* Better word for "anchor": reference benchmark

Contents:

* The goal: fastest possible intrinsics, we'll start with sin

* We'll create a benchmark of a loop of sin(sin(sin(sin(x)))) N times to have
  enough computation and use loop tiling to achieve maximum performance. Show
  that without loop tiling we will lose performance. If done right, even in
  main memory things run essentially at the L1 cache performance. Then we use
  this ultimate benchmark with all implementations (gfortran, intel, openlibm,
  ...). This benchmark then shows all techniques for speed: tiling, L1
  theoretical performance peak, assembly to achieve it, benchmarking
  infrastructure, etc. Calculating the percentage of peak.

* We will only do single core / serial implementation. Both Intel and ARM.

* compare and understand accuracy (gfortran's sin accurate to the last bit, but
  there is a performance price for that), we are ok if last few bits are
  inaccurate, but we want the absolute best performance

* Performance: theoretical peak, how to achieve it (in assembly if needed), all
  the above stuff

* Get back from assembly into Fortran / LLVM, still achieve the peak. We should
  benchmark LFortran itself. Show a path forward via LLVM.

* Benchmark other fast `sin` libraries out there --- MKL, Intel Ifort, there
  are SIMD math libraries. Benchmark them all. Both for accuracy and speed.

* There are two approaches to math functions (intrinsic and non-intrinsic). In
  Debug mode, we want use accuracy first, performance second. In Release mode
  we want to use performance first, accuracy second. We want to include both in
  LFortran. For the accurate versions, we can simply use existing math routines
  such as from `openlibm`. For the performance first versions, we have to
  implement our own, and show that we are getting maximum performance. The
  content of this blog post series.

* GFortran's `sin` (in both Debug/Release mode) is following accuracy first
  approach. About 83% of all cases are exactly rounded, 17% is 1 ULP from the
  exactly rounded double precision floating point answer. To get that accuracy,
  a careful argument reduction is done To get that accuracy, a careful argument
  reduction is done, and argument + tail is passed to the sin kernel (even
  though both are possibly accurate to the last bit) in order not to lose the
  last bit with double rounding. There are several if statements (branching),
  overall making it very accurate, but slow.

* For performance first, we investigate roughly along the following lines:

* What is the fastest way to evaluate the kernel, say on [-pi/4,pi/4]? We find
  that we have to evaluate at least 5 terms. We end up evaluating 8 terms and
  get accuracy on [-pi/2, pi/2]. A tiny bit slower for the kernel, but saves on
  argument reduction.

* What is the fastest way to do argument reduction? One of the fastest is
  branch free int() plus extended modular arithmetic (3 terms), which is
  accurate up to x ~ 1e10. Regular `modulo` cannot be used, as it loses
  accuracy quickly, already for x > 30.

* Using this approach, we find the minimal algorithm, with theoretical
  performance peak of about ~2.5 cycles per double. We then achieve over 50% of
  this peak with pure Fortran implementation, on both Intel and ARM.

* If we wanted the absolute best performance, we would get rid of the extended
  precision (saves about 0.375 cycle per double), so not much and we lose
  accuracy for x > 30. We also don't need to do reduction at all if we only
  want to use x from [-pi/2, pi/2]. Then the peak is about 1.75 cycles. For the
  kernel, we can also reduce the polynomial to less terms, for lower accuracy.
  We can save a few fmas, so perhaps peak at ~ 1.00 cycles.

* Overall, as can be seen, even the most performing approach will not be much
  faster than the current peak of 2.5 cycles per double, but it will be a lot
  less accurate.

* Our goal is sin(x) working at least for [-5000, 5000]. In this range, the
  extended precision is needed for argument reduction. The fastest
  implementation is with 3 terms, as we already use. And those happen to be
  accurate all the way to x ~ 1e10.

* It seems our current implementation is the fastest version that is still
  usasble in practice. Any faster version will lose accuracy quickly, and even
  then it can only get a peak of ~ 1.625 cycles, so only 1.6x faster. It
  cannot get any faster than that anyway, as at least a few terms must be
  evaluated, and the argument reduction still has to do int(), min, max, min.
  So our usable version has a peak within 2x of the absolute best performing
  version. We are over 50% of the peak, so total we are within a factor of 4x
  of the best theoretical speed of the fastest way one can even compute sin(),
  and it would not even be very accurate.

* Exact theoretical peak for the absolute minimum version:
  (3*fma_clock + 2*mul_clock) + (3*max_clock + 2*float_int_conv_clock + mul_clock)
  On Intel it gives 1.625


---------------------

Appollo Guidance Computer (AGC):

* https://space.stackexchange.com/questions/30952/how-did-the-apollo-computers-evaluate-transcendental-functions-like-sine-arctan

They compute `sin(pi*x)`. The 16-bit fixed-point number could only store
values from -1 to 1., so during the computation the argument is scaled by 2 to
fit within this range.

They used a polynomial approximation of the form x*(C1+x^2*(C2+x^2*C3)) to
approximate sin(x*pi/2)/2 (they double the argument first, and the multiply by
two at the end):

C1 = 0.0363551
C2 = -0.3216147
C3 = 0.7853134

The range is (-pi/2, pi/2) and the accuracy is about 1e-4 on this range. There
was no argument reduction.


------------------

Our current Blog.md (9/29/21) version hits all the points above. In the full
set of blog posts we can expand on:

* Benchmarking other libraries like MKL and Julia
* Mention the AGC
* Add ARM benchmark results

Plan for a series of blog posts:

* Post 1: Intro+Design+Accuracy
* Post 2: Performance I --- more of a summary (hitting the main points and
  results, sometimes light on detail)
* Post 3: Performance II --- full details of everything
* Post 4: Cos(x) ---- cos(x) = sin(x+pi/2)
* Post 5: Tan(x) ---- sin(x)/cos(x) or reduction + poly fit
* Post 6: Exp(x)
* ...
